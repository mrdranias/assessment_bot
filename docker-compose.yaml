services:
  # PostgreSQL Database
  postgres:
    image: postgres:15-alpine
    container_name: adl_postgres
    environment:
      POSTGRES_DB: adl_assessment
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: password123
      PGPASSWORD: password123
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./database/init.sql:/docker-entrypoint-initdb.d/init.sql
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres -d adl_assessment"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - adl_network

  # Neo4j Graph Database
  neo4j:
    image: neo4j:5.14-community
    container_name: adl_neo4j
    environment:
      NEO4J_AUTH: neo4j/password123
      NEO4J_dbms_default__database: neo4j
      NEO4J_dbms_memory_heap_initial__size: 512m
      NEO4J_dbms_memory_heap_max__size: 1G
      NEO4J_dbms_memory_pagecache_size: 512m
      NEO4J_PLUGINS: '["apoc"]'
    ports:
      - "7474:7474"  # HTTP
      - "7687:7687"  # Bolt
    volumes:
      - neo4j_data:/data
      - neo4j_logs:/logs
      - ./db/neo4j_init:/docker-entrypoint-initdb.d
    healthcheck:
      test: ["CMD", "cypher-shell", "-u", "neo4j", "-p", "password123", "RETURN 1"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - adl_network

  # FastAPI Backend
  api:
    build:
      context: .
      dockerfile: Dockerfile.api
    container_name: adl_api
    environment:
      # Database Configuration
      POSTGRES_HOST: postgres
      POSTGRES_PORT: 5432
      POSTGRES_DB: adl_assessment
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: password123
      
      # Neo4j Configuration
      NEO4J_URI: bolt://neo4j:7687
      NEO4J_USER: neo4j
      NEO4J_PASSWORD: password123
      NEO4J_DATABASE: neo4j
      
      # LLM Configuration
      LLM_PROVIDER: openai
      OPENAI_API_KEY: ${OPENAI_API_KEY}
      OPENAI_MODEL: gpt-4o
      
      # Application Configuration
      APP_HOST: 0.0.0.0
      APP_PORT: 8000
      LOG_LEVEL: INFO
      PYTHONPATH: /app
    ports:
      - "8000:8000"
    depends_on:
      postgres:
        condition: service_healthy
      neo4j:
        condition: service_healthy
    volumes:
      - ./api:/app/api
      - ./logs:/app/logs
    command: ["uvicorn", "api.main:app", "--host", "0.0.0.0", "--port", "8000", "--reload"]
    networks:
      - adl_network

  # Gradio UI
  ui:
    build:
      context: .
      dockerfile: Dockerfile.ui
    container_name: adl_ui
    environment:
      API_BASE_URL: http://api:8000
    ports:
      - "7860:7860"  # Gradio dashboard
      - "8888:8888"  # Jupyter Lab (optional)
    depends_on:
      - api
    volumes:
      - ./ui:/app/ui  # Live UI development
    networks:
      - adl_network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:7860"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Ollama LLM Service
  ollama:
    container_name: adl_ollama
    image: ollama/ollama:latest
    healthcheck: 
      test: ["CMD", "ollama", "--version"]
      interval: 30s
      retries: 2
      start_period: 10s
      timeout: 10s
    ports:
      - "11434:11434"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - OLLAMA_KEEP_ALIVE=1200
      - OLLAMA_LOG_LEVEL=DEBUG
      - OLLAMA_MODELS=/root/.ollama/models
    volumes:
      - /mnt/e/PROJECTS/LLM_servers/ollama:/root/.ollama
    networks:
      - adl_network

networks:
  adl_network:
    driver: bridge

volumes:
  postgres_data:
  neo4j_data:
  neo4j_logs:
